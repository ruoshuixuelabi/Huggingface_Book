{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b862ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T08:40:37.833505400Z",
     "start_time": "2023-08-15T08:40:36.042747300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'precision', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'code_eval', 'type': 'metric', 'community': False, 'likes': 10}, {'name': 'roc_auc', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'cuad', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'xnli', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'rouge', 'type': 'metric', 'community': False, 'likes': 19}, {'name': 'pearsonr', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'mse', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'super_glue', 'type': 'metric', 'community': False, 'likes': 4}, {'name': 'comet', 'type': 'metric', 'community': False, 'likes': 4}, {'name': 'cer', 'type': 'metric', 'community': False, 'likes': 7}, {'name': 'sacrebleu', 'type': 'metric', 'community': False, 'likes': 8}, {'name': 'mahalanobis', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'wer', 'type': 'metric', 'community': False, 'likes': 13}, {'name': 'competition_math', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'f1', 'type': 'metric', 'community': False, 'likes': 2}, {'name': 'recall', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'coval', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'mauve', 'type': 'metric', 'community': False, 'likes': 4}, {'name': 'xtreme_s', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'bleurt', 'type': 'metric', 'community': False, 'likes': 8}, {'name': 'ter', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'accuracy', 'type': 'metric', 'community': False, 'likes': 12}, {'name': 'exact_match', 'type': 'metric', 'community': False, 'likes': 3}, {'name': 'indic_glue', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'spearmanr', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'mae', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'squad', 'type': 'metric', 'community': False, 'likes': 4}, {'name': 'chrf', 'type': 'metric', 'community': False, 'likes': 8}, {'name': 'glue', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'perplexity', 'type': 'metric', 'community': False, 'likes': 9}, {'name': 'mean_iou', 'type': 'metric', 'community': False, 'likes': 2}, {'name': 'squad_v2', 'type': 'metric', 'community': False, 'likes': 2}, {'name': 'meteor', 'type': 'metric', 'community': False, 'likes': 5}, {'name': 'bleu', 'type': 'metric', 'community': False, 'likes': 19}, {'name': 'wiki_split', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'sari', 'type': 'metric', 'community': False, 'likes': 5}, {'name': 'frugalscore', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'google_bleu', 'type': 'metric', 'community': False, 'likes': 5}, {'name': 'bertscore', 'type': 'metric', 'community': False, 'likes': 18}, {'name': 'matthews_correlation', 'type': 'metric', 'community': False, 'likes': 7}, {'name': 'seqeval', 'type': 'metric', 'community': False, 'likes': 14}, {'name': 'trec_eval', 'type': 'metric', 'community': False, 'likes': 3}, {'name': 'rl_reliability', 'type': 'metric', 'community': False, 'likes': 2}, {'name': 'angelina-wang/directional_bias_amplification', 'type': 'metric', 'community': True, 'likes': 5}, {'name': 'cpllab/syntaxgym', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'kaggle/ai4code', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'codeparrot/apps_metric', 'type': 'metric', 'community': True, 'likes': 5}, {'name': 'mfumanelli/geometric_mean', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'poseval', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'brier_score', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'abidlabs/mean_iou', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'abidlabs/mean_iou2', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'giulio98/codebleu', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'mase', 'type': 'metric', 'community': False, 'likes': 1}, {'name': 'mape', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'smape', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'dvitel/codebleu', 'type': 'metric', 'community': True, 'likes': 3}, {'name': 'NCSOFT/harim_plus', 'type': 'metric', 'community': True, 'likes': 8}, {'name': 'JP-SystemsX/nDCG', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Drunper/metrica_tesi', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'jpxkqx/peak_signal_to_noise_ratio', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'jpxkqx/signal_to_reconstruction_error', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'hpi-dhc/FairEval', 'type': 'metric', 'community': True, 'likes': 4}, {'name': 'nist_mt', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'lvwerra/accuracy_score', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'character', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'charcut_mt', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'ybelkada/cocoevaluate', 'type': 'metric', 'community': True, 'likes': 2}, {'name': 'harshhpareek/bertscore', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'posicube/mean_reciprocal_rank', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'bstrai/classification_report', 'type': 'metric', 'community': True, 'likes': 2}, {'name': 'omidf/squad_precision_recall', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Josh98/nl2bash_m', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'BucketHeadP65/confusion_matrix', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'BucketHeadP65/roc_curve', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'yonting/average_precision_score', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'transZ/test_parascore', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'transZ/sbert_cosine', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'hynky/sklearn_proxy', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'unnati/kendall_tau_distance', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'r_squared', 'type': 'metric', 'community': False, 'likes': 0}, {'name': 'Viona/fuzzy_reordering', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Viona/kendall_tau', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'lhy/hamming_loss', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'lhy/ranking_loss', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Muennighoff/code_eval_octopack', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'yuyijiong/quad_match_score', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'Splend1dchan/cosine_similarity', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'Yeshwant123/mcc', 'type': 'metric', 'community': True, 'likes': 2}, {'name': 'transformersegmentation/segmentation_scores', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'sma2023/wil', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'chanelcolgate/average_precision', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'ckb/unigram', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Felipehonorato/eer', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'manueldeprada/beer', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'tialaeMceryu/unigram', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'He-Xingwei/sari_metric', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'langdonholmes/cohen_weighted_kappa', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'fschlatt/ner_eval', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'hyperml/balanced_accuracy', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'brian920128/doc_retrieve_metrics', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'guydav/restrictedpython_code_eval', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'k4black/codebleu', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Natooz/ece', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'ingyu/klue_mrc', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'Vipitis/shadermatch', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'unitxt/metric', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'gabeorlanski/bc_eval', 'type': 'metric', 'community': True, 'likes': 1}, {'name': 'jjkim0807/code_eval', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'vichyt/metric-codebleu', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'agkhalil/ragene_metrics', 'type': 'metric', 'community': True, 'likes': 0}, {'name': 'mcnemar', 'type': 'comparison', 'community': False, 'likes': 1}, {'name': 'exact_match', 'type': 'comparison', 'community': False, 'likes': 0}, {'name': 'wilcoxon', 'type': 'comparison', 'community': False, 'likes': 0}, {'name': 'kaleidophon/almost_stochastic_order', 'type': 'comparison', 'community': True, 'likes': 1}, {'name': 'word_length', 'type': 'measurement', 'community': False, 'likes': 0}, {'name': 'lvwerra/element_count', 'type': 'measurement', 'community': True, 'likes': 0}, {'name': 'word_count', 'type': 'measurement', 'community': False, 'likes': 0}, {'name': 'text_duplicates', 'type': 'measurement', 'community': False, 'likes': 0}, {'name': 'perplexity', 'type': 'measurement', 'community': False, 'likes': 3}, {'name': 'label_distribution', 'type': 'measurement', 'community': False, 'likes': 1}, {'name': 'toxicity', 'type': 'measurement', 'community': False, 'likes': 4}, {'name': 'regard', 'type': 'measurement', 'community': False, 'likes': 2}, {'name': 'honest', 'type': 'measurement', 'community': False, 'likes': 3}, {'name': 'ybelkada/toxicity', 'type': 'measurement', 'community': True, 'likes': 0}, {'name': 'ronaldahmed/ccl_win', 'type': 'measurement', 'community': True, 'likes': 0}, {'name': 'meg/perplexity', 'type': 'measurement', 'community': True, 'likes': 0}, {'name': 'cakiki/tokens_per_byte', 'type': 'measurement', 'community': True, 'likes': 0}, {'name': 'lsy641/distinct', 'type': 'measurement', 'community': True, 'likes': 1}]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(122, ['accuracy', 'bertscore', 'bleu', 'bleurt', 'brier_score'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第4章/列出可用的评价指标\n",
    "from datasets import list_metrics\n",
    "import evaluate\n",
    "metrics_list1=evaluate.list_evaluation_modules(with_details =True)\n",
    "print(metrics_list1)\n",
    "# 之前版本打印指标\n",
    "metrics_list = list_metrics()\n",
    "# 打印指标的长度 以及指标的前5个内容\n",
    "len(metrics_list), metrics_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d699a36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
      "Args:\n",
      "    predictions: list of predictions to score.\n",
      "        Each translation should be tokenized into a list of tokens.\n",
      "    references: list of lists of references for each translation.\n",
      "        Each reference should be tokenized into a list of tokens.\n",
      "Returns: depending on the GLUE subset, one or several of:\n",
      "    \"accuracy\": Accuracy\n",
      "    \"f1\": F1 score\n",
      "    \"pearson\": Pearson Correlation\n",
      "    \"spearmanr\": Spearman Correlation\n",
      "    \"matthews_correlation\": Matthew Correlation\n",
      "Examples:\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'accuracy': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'accuracy': 1.0, 'f1': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
      "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
      "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
      "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'matthews_correlation': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#第4章/加载一个评价指标\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(path='glue', config_name='mrpc')\n",
    "\n",
    "print(metric.inputs_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5711e3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666, 'f1': 0.6666666666666666}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第4章/计算一个评价指标\n",
    "predictions = [0, 1, 0]\n",
    "references = [0, 1, 1]\n",
    "\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
