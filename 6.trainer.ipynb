{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4b4554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:28:58.100361Z",
     "start_time": "2023-08-17T02:28:57.148279100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "BertTokenizerFast(name_or_path='hfl/rbt3', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/加载tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('hfl/rbt3')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3086c2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:28:58.149398700Z",
     "start_time": "2023-08-17T02:28:58.103634100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': [[101, 3209, 3299, 6163, 7652, 749, 872, 4638, 4970, 2094, 102], [101, 872, 6163, 7652, 749, 1166, 782, 4638, 3457, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/试编码句子\n",
    "tokenizer.batch_encode_plus(\n",
    "    ['明月装饰了你的窗子', '你装饰了别人的梦'],\n",
    "    truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd8341a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:28:58.202926500Z",
     "start_time": "2023-08-17T02:28:58.131211800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 0\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 100\n    })\n})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/从磁盘加载数据集\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "\n",
    "#缩小数据规模，便于测试\n",
    "dataset['train'] = dataset['train'].shuffle().select(range(2000))\n",
    "dataset['test'] = dataset['test'].shuffle().select(range(100))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996c8e5a",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T02:31:51.876799200Z",
     "start_time": "2023-08-17T02:31:45.605899800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fa27183df9c4961b79d308097c58c83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f64dc6263b84bc292c8aafa3b7ebb01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['label'],\n        num_rows: 0\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 100\n    })\n})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/编码\n",
    "def f(data):\n",
    "    return tokenizer.batch_encode_plus(data['text'], truncation=True)\n",
    "\n",
    "\n",
    "dataset = dataset.map(f,\n",
    "                      batched=True,\n",
    "                      batch_size=1000,\n",
    "                      num_proc=4,\n",
    "                      remove_columns=['text'])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196060e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:32:02.305098100Z",
     "start_time": "2023-08-17T02:31:57.484638600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Filter (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e560d5aa9bc4473b782a7bb5fbbdd75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c4b15f96b6c4afbba360f8d3da3111d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1974\n    })\n    validation: Dataset({\n        features: ['label'],\n        num_rows: 0\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 99\n    })\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/移除太长的句子\n",
    "def f(data):\n",
    "    return [len(i) <= 512 for i in data['input_ids']]\n",
    "\n",
    "\n",
    "dataset = dataset.filter(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad583ee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:35:14.576917900Z",
     "start_time": "2023-08-17T02:32:07.756198100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/156M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e94a984bc5f4a61bacb04d21345b730"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "3847.8338"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/加载模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3',\n",
    "                                                           num_labels=2)\n",
    "\n",
    "#统计模型参数量\n",
    "sum([i.nelement() for i in model.parameters()]) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5bde364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:35:22.662361600Z",
     "start_time": "2023-08-17T02:35:21.767612600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(0.5065, grad_fn=<NllLossBackward0>), torch.Size([4, 2]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/模型试算\n",
    "import torch\n",
    "\n",
    "#模拟一批数据\n",
    "data = {\n",
    "    'input_ids': torch.ones(4, 10, dtype=torch.long),\n",
    "    'token_type_ids': torch.ones(4, 10, dtype=torch.long),\n",
    "    'attention_mask': torch.ones(4, 10, dtype=torch.long),\n",
    "    'labels': torch.ones(4, dtype=torch.long)\n",
    "}\n",
    "\n",
    "#模型试算\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dec01a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:35:28.227769500Z",
     "start_time": "2023-08-17T02:35:28.222786100Z"
    }
   },
   "outputs": [],
   "source": [
    "# #第6章/加载评价指标\n",
    "# from datasets import load_metric\n",
    "\n",
    "# metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "403170ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:36:01.926135Z",
     "start_time": "2023-08-17T02:35:30.489533200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.75}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/定义评价函数\n",
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = logits.argmax(axis=1)\n",
    "    return {'accuracy': (logits == labels).sum() / len(labels)}\n",
    "    #return metric.compute(predictions=logits, references=labels)\n",
    "\n",
    "\n",
    "#模拟输出\n",
    "eval_pred = EvalPrediction(\n",
    "    predictions=np.array([[0, 1], [2, 3], [4, 5], [6, 7]]),\n",
    "    label_ids=np.array([1, 1, 0, 1]),\n",
    ")\n",
    "\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86c46ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:40:04.728406300Z",
     "start_time": "2023-08-17T02:39:59.374287600Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/定义训练参数\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "#定义训练参数\n",
    "args = TrainingArguments(\n",
    "    #定义临时数据保存路径\n",
    "    output_dir='./output_dir',\n",
    "\n",
    "    #定义测试执行的策略，可取值no、epoch、steps\n",
    "    evaluation_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step执行一次测试\n",
    "    eval_steps=30,\n",
    "\n",
    "    #定义模型保存策略，可取值no、epoch、steps\n",
    "    save_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step保存一次\n",
    "    save_steps=30,\n",
    "\n",
    "    #定义共训练几个轮次\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    #定义学习率\n",
    "    learning_rate=1e-4,\n",
    "\n",
    "    #加入参数权重衰减，防止过拟合\n",
    "    weight_decay=1e-2,\n",
    "\n",
    "    #定义测试和训练时的批次大小\n",
    "    per_device_eval_batch_size=16,\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    #定义是否要使用gpu训练\n",
    "    no_cuda=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5748cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:41:15.630623700Z",
     "start_time": "2023-08-17T02:41:15.039930900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 11\u001B[0m\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSequenceClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhfl/rbt3\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      6\u001B[0m                                                            num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#定义训练器\u001B[39;00m\n\u001B[0;32m      8\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m      9\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     10\u001B[0m     args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m---> 11\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39m\u001B[43mdataset\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     12\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mdataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     13\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m     14\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mDataCollatorWithPadding(tokenizer),\n\u001B[0;32m     15\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#第6章/定义训练器\n",
    "from transformers import Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3',\n",
    "                                                           num_labels=2)\n",
    "#定义训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1ee63",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.583990300Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/测试数据整理函数\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "#获取一批数据\n",
    "data = dataset['train'][:5]\n",
    "\n",
    "#输出这些句子的长度\n",
    "for i in data['input_ids']:\n",
    "    print(len(i))\n",
    "\n",
    "#调用数据整理函数\n",
    "data = data_collator(data)\n",
    "\n",
    "#查看整理后的数据\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac07ba4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.584987200Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7508e31",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.586981200Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861051f",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.588974300Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971dd75",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.588974300Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/从某个存档继续训练\n",
    "trainer.train(resume_from_checkpoint='./output_dir/checkpoint-90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc37ac",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.589971100Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d024896",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.590967500Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/手动保存模型参数\n",
    "trainer.save_model(output_dir='./output_dir/save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386463d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-17T02:28:59.591964200Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/手动加载模型参数\n",
    "import torch\n",
    "\n",
    "model.load_state_dict(torch.load('./output_dir/save_model/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f3818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T02:28:59.593957700Z",
     "start_time": "2023-08-17T02:28:59.592961200Z"
    }
   },
   "outputs": [],
   "source": [
    "#第6章/测试\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(trainer.get_eval_dataloader()):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    data[k] = v.to('cuda')\n",
    "\n",
    "out = model(**data)\n",
    "out = out['logits'].argmax(dim=1)\n",
    "\n",
    "for i in range(16):\n",
    "    print(tokenizer.decode(data['input_ids'][i], skip_special_tokens=True))\n",
    "    print('label=', data['labels'][i].item())\n",
    "    print('predict=', out[i].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
